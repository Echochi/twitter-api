{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_Sentiment_Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ujearRUYZ773",
        "kOyfII-_mq2P"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Echochi/twitter-api/blob/master/Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JtYPc6AaG86",
        "colab_type": "text"
      },
      "source": [
        "# Pip installed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylbZBDJCcb9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6SNoojXchqj",
        "colab_type": "text"
      },
      "source": [
        "# Tweet Sentiment Anaylsis\n",
        "https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4nr_pd4G1GF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1f8888b3-9510-452e-92fe-2c06e50aeafd"
      },
      "source": [
        "# Code to read csv file into colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#2. Get the file\n",
        "downloaded = drive.CreateFile({'id':'1HxpKJ2ffcnCXonh8_fam7bSZrK_i8lf-'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('twitter_access_tokens.py')  \n",
        "\n",
        "# #3. Read file as panda dataframe\n",
        "# import pandas as pd\n",
        "# xyz = pd.read_csv('view_data.csv') "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 5.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 5.2MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQUaztDBWdGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "import tweepy \n",
        "from tweepy import OAuthHandler \n",
        "from textblob import TextBlob "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujearRUYZ773",
        "colab_type": "text"
      },
      "source": [
        "# Original Code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5TDLJ1TWhvS",
        "colab_type": "code",
        "outputId": "06af2849-0f8e-413b-bf7d-317670496cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "class TwitterClient(object): \n",
        "    ''' \n",
        "    Generic Twitter Class for sentiment analysis. \n",
        "    '''\n",
        "    def __init__(self): \n",
        "        ''' \n",
        "        Class constructor or initialization method. \n",
        "        '''\n",
        "        # keys and tokens from the Twitter Dev Console \n",
        "        consumer_key = 'v7FWcDvxrKmfM6SDrKjtTGFmM'\n",
        "        consumer_secret = 'wmi0x5piLXLjCpqIDJIZkmXIIWbhI3ONjfcAd3CDoH8UaIhaV3'\n",
        "        access_token = '519628145-QN6xePHht2ZF6ln6vY4y1U98gVJzU3IuHN5n46JS'\n",
        "        access_token_secret = 'LC1KkBYZohzqjxZZ9PUQ640B98ZjaiV50MoHSmsJLpYFH'\n",
        "  \n",
        "        # attempt authentication \n",
        "        try: \n",
        "            # create OAuthHandler object \n",
        "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
        "            # set access token and secret \n",
        "            self.auth.set_access_token(access_token, access_token_secret) \n",
        "            # create tweepy API object to fetch tweets \n",
        "            self.api = tweepy.API(self.auth) \n",
        "        except: \n",
        "            print(\"Error: Authentication Failed\") \n",
        "  \n",
        "    def clean_tweet(self, tweet): \n",
        "        ''' \n",
        "        Utility function to clean tweet text by removing links, special characters \n",
        "        using simple regex statements. \n",
        "        '''\n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
        "  \n",
        "    def get_tweet_sentiment(self, tweet): \n",
        "        ''' \n",
        "        Utility function to classify sentiment of passed tweet \n",
        "        using textblob's sentiment method \n",
        "        '''\n",
        "        # create TextBlob object of passed tweet text \n",
        "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
        "        # set sentiment \n",
        "        if analysis.sentiment.polarity > 0: \n",
        "            return 'positive'\n",
        "        elif analysis.sentiment.polarity == 0: \n",
        "            return 'neutral'\n",
        "        else: \n",
        "            return 'negative'\n",
        "  \n",
        "    def get_tweets(self, query, count = 10): \n",
        "        ''' \n",
        "        Main function to fetch tweets and parse them. \n",
        "        '''\n",
        "        # empty list to store parsed tweets \n",
        "        tweets = [] \n",
        "  \n",
        "        try: \n",
        "            # call twitter api to fetch tweets \n",
        "            fetched_tweets = self.api.search(q = query, count = count) \n",
        "  \n",
        "            # parsing tweets one by one \n",
        "            for tweet in fetched_tweets: \n",
        "                # empty dictionary to store required params of a tweet \n",
        "                parsed_tweet = {} \n",
        "  \n",
        "                # saving text of tweet \n",
        "                parsed_tweet['text'] = tweet.text \n",
        "                # saving sentiment of tweet \n",
        "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
        "  \n",
        "                # appending parsed tweet to tweets list \n",
        "                if tweet.retweet_count > 0: \n",
        "                    # if tweet has retweets, ensure that it is appended only once \n",
        "                    if parsed_tweet not in tweets: \n",
        "                        tweets.append(parsed_tweet) \n",
        "                else: \n",
        "                    tweets.append(parsed_tweet) \n",
        "  \n",
        "            # return parsed tweets \n",
        "            return tweets \n",
        "  \n",
        "        except tweepy.TweepError as e: \n",
        "            # print error (if any) \n",
        "            print(\"Error : \" + str(e)) \n",
        "  \n",
        "def main(): \n",
        "    # creating object of TwitterClient Class \n",
        "    api = TwitterClient() \n",
        "    # calling function to get tweets \n",
        "    tweets = api.get_tweets(query = 'Donald Trump', count = 200) \n",
        "  \n",
        "    # picking positive tweets from tweets \n",
        "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
        "    # percentage of positive tweets \n",
        "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
        "    # picking negative tweets from tweets \n",
        "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
        "    # percentage of negative tweets \n",
        "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
        "    # percentage of neutral tweets \n",
        "    print(\"Neutral tweets percentage: {} %\".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
        "  \n",
        "    # printing first 5 positive tweets \n",
        "    print(\"\\n\\nPositive tweets:\") \n",
        "    for tweet in ptweets[:10]: \n",
        "        print(tweet['text']) \n",
        "  \n",
        "    # printing first 5 negative tweets \n",
        "    print(\"\\n\\nNegative tweets:\") \n",
        "    for tweet in ntweets[:10]: \n",
        "        print(tweet['text']) \n",
        "  \n",
        "if __name__ == \"__main__\": \n",
        "    # calling main function \n",
        "    main() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error : [{'code': 89, 'message': 'Invalid or expired token.'}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5d389e60953c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# calling main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-5d389e60953c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# picking positive tweets from tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mptweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;31m# percentage of positive tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Positive tweets percentage: {} %\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsZ0oXcxaBTW",
        "colab_type": "text"
      },
      "source": [
        "# Execute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y40jOahkWsce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init(): \n",
        "        ''' \n",
        "        Class constructor or initialization method. \n",
        "        '''\n",
        "        # keys and tokens from the Twitter Dev Console \n",
        "        import twitter_access_tokens\n",
        "        consumer_key = twitter_access_tokens.consumer_key\n",
        "        consumer_secret = twitter_access_tokens.consumer_secret\n",
        "        access_token = twitter_access_tokens.access_token\n",
        "        access_token_secret = twitter_access_tokens.access_token_secret\n",
        "        # attempt authentication \n",
        "        try: \n",
        "            # create OAuthHandler object \n",
        "            auth = OAuthHandler(consumer_key, consumer_secret) \n",
        "            # set access token and secret \n",
        "            auth.set_access_token(access_token, access_token_secret) \n",
        "            # create tweepy API object to fetch tweets \n",
        "            api = tweepy.API(auth) \n",
        "            return api\n",
        "        except: \n",
        "            print(\"Error: Authentication Failed\") \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zclkcsHsKDFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "131aefa2-5ca1-432d-bf5f-de1d4e4371e5"
      },
      "source": [
        "init()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tweepy.api.API at 0x7f2393288390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQhAKE_hqDWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def clean_tweet(tweet): \n",
        "        ''' \n",
        "        Utility function to clean tweet text by removing links, special characters \n",
        "        using simple regex statements. \n",
        "        '''\n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq3RjhndqOqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   def get_tweet_sentiment(tweet): \n",
        "        ''' \n",
        "        Utility function to classify sentiment of passed tweet \n",
        "        using textblob's sentiment method \n",
        "        '''\n",
        "        # create TextBlob object of passed tweet text \n",
        "        analysis = TextBlob(clean_tweet(tweet)) \n",
        "        # set sentiment \n",
        "        if analysis.sentiment.polarity > 0: \n",
        "            return 'positive', analysis.sentiment.polarity\n",
        "        elif analysis.sentiment.polarity == 0: \n",
        "            return 'neutral', analysis.sentiment.polarity\n",
        "        else: \n",
        "            return 'negative', analysis.sentiment.polarity\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xesgpJLYqcKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def get_tweets(api, query, count = 10): \n",
        "        ''' \n",
        "        Main function to fetch tweets and parse them. \n",
        "        '''\n",
        "        # empty list to store parsed tweets \n",
        "        tweets = [] \n",
        "  \n",
        "        try: \n",
        "            # call twitter api to fetch tweets \n",
        "            fetched_tweets = api.search(q=query, count=count, tweet_mode='extended') \n",
        "  \n",
        "            # parsing tweets one by one \n",
        "            for tweet in fetched_tweets: \n",
        "                # empty dictionary to store required params of a tweet \n",
        "                parsed_tweet = {} \n",
        "                \n",
        "                # get full text\n",
        "                if 'retweeted_status' in tweet._json:\n",
        "                    full_text = 'RT ' + tweet._json['retweeted_status']['full_text']\n",
        "                else:\n",
        "                    full_text = tweet._json['full_text']\n",
        "                    \n",
        "                # saving text of tweet \n",
        "                parsed_tweet['text'] = full_text\n",
        "                # saving sentiment of tweet \n",
        "                parsed_tweet['sentiment'], parsed_tweet['score'] = get_tweet_sentiment(full_text) \n",
        "  \n",
        "                # appending parsed tweet to tweets list \n",
        "                if 'retweeted_status' in tweet._json:\n",
        "                    # if tweet has retweets, ensure that it is appended only once \n",
        "                    if parsed_tweet not in tweets: \n",
        "                        tweets.append(parsed_tweet) \n",
        "                else: \n",
        "                    tweets.append(parsed_tweet) \n",
        "  \n",
        "            # return parsed tweets \n",
        "            return tweets \n",
        "  \n",
        "        except tweepy.TweepError as e: \n",
        "            # print error (if any) \n",
        "            print(\"Error : \" + str(e)) \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhI_J7b0eZnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_average_sentiment(tweets):\n",
        "  '''\n",
        "  Cycle through tweet sentiment scores to get average sentiment of all tweets.\n",
        "  '''\n",
        "  total_score = 0\n",
        " \n",
        "  if len(tweets) != 0:\n",
        "    # add all scores\n",
        "    for parsed_tweet in tweets:\n",
        "      total_score += parsed_tweet['score']\n",
        "    \n",
        "    return total_score/len(tweets)\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    return len(tweets)\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOyfII-_mq2P",
        "colab_type": "text"
      },
      "source": [
        "# Test tweet API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmv3EXMBrh94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = get_tweets(api, query = 'Donald Trump', count = 20)\n",
        "tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh33QO53io1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fetched_tweets = api.search(q='Donald Trump', count=20, tweet_mode='extended') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9-DrW_lqiTm",
        "colab_type": "code",
        "outputId": "973905a6-2c3d-4c88-f440-270f1eb772ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(fetched_tweets[1]._json['full_text'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@AOC you are in way over your head but you are really cute! Big fan! Keep talking! The more you talk the better it is for Donald Trump!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViWbeIeEmGhC",
        "colab_type": "code",
        "outputId": "05b6ab0a-6938-4469-e76c-9ffc591aa85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for tweet in fetched_tweets:\n",
        "    if 'retweeted_status' in tweet._json:\n",
        "                    print('RT ' + tweet._json['retweeted_status']['full_text'])\n",
        "    else:\n",
        "                    print(tweet._json['full_text'])\n",
        "               "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT Donald Trump: go back to where you came from\n",
            "\n",
            "Geraldo Rivera: hey that’s racist\n",
            "\n",
            "Brit Hume: no that’s not racist\n",
            "\n",
            "Lindsey Graham: I love racism\n",
            "\n",
            "Susan Collins: I have a hangnail\n",
            "@AOC you are in way over your head but you are really cute! Big fan! Keep talking! The more you talk the better it is for Donald Trump!\n",
            "RT These four women are expressing more patriotism in this one press conference than Donald Trump has in his entire life.\n",
            "RT If you still support Donald Trump at this point, you are a racist. \n",
            "\n",
            "I'm not afraid to say it. \n",
            "\n",
            "#RacistPresident\n",
            "RT Donald Trump puts babies in cages. \n",
            "Donald Trump puts babies in cages. \n",
            "Donald Trump puts babies in cages. \n",
            "Donald Trump puts babies in cages. \n",
            "Donald Trump puts babies in cages. \n",
            "Donald Trump puts babies in cages. \n",
            "Donald Trump puts babies in cages. \n",
            "#RacistPresident\n",
            "RT Hundreds of roads, parks, schools and other landmarks have been named in honor of @BarackObama since he left office. What do you think will be named after Donald Trump? https://t.co/f4JzXYAxIO\n",
            "Donald Trump: 'Don't take the bait', US congresswomen say\n",
            "\n",
            "The US congresswomen attacked by the president in racially charged tweets dismiss them as a distraction. \n",
            "\n",
            "https://t.co/FGUQFdyU3u\n",
            "\n",
            "#NEWS\n",
            "#BBC\n",
            "#BritishBroadcastingCorporation https://t.co/XVHOzJt0iP\n",
            "@realDonaldTrump Donald Trump is a RACIST, please understand that the doctrine and opinions expressed do not reflect the views of the majority of Americans in this country. You can not hide incompetence and ignorance behind racism, it just makes you look stupid. https://t.co/RxEwGbHf1i\n",
            "RT After Donald Trump says people should go back to their own countries if they’re unhappy in America, one woman immediately boards a one-way flight to Slovenia: https://t.co/zEHWR99bty\n",
            "RT The 100% truth ... \n",
            "\n",
            "President Donald J Trump never has been and never will be a racist.\n",
            "\n",
            "Alexandria Ocasio-Cortez of New York, Ilhan Omar of Minnesota and Rashida Tlaib of Michigan are all racists on steroids.\n",
            "RT Donald Trump accused of running US with 'white nationalist agenda' https://t.co/ki0HIADCie\n",
            "RT Donald Trump: go back to where you came from\n",
            "\n",
            "Geraldo Rivera: hey that’s racist\n",
            "\n",
            "Brit Hume: no that’s not racist\n",
            "\n",
            "Lindsey Graham: I love racism\n",
            "\n",
            "Susan Collins: I have a hangnail\n",
            "RT Donald Trump has told “progressive Democrat congresswomen”, 3 born in the US, to “go back and help fix the totally broken and crime infested places from which they came”. He still can't cope with the reality that a better non-racist President preceded him.\n",
            "RT ⚡️#RacistPresident trends on Twitter after Donald Trump's attack on congresswomen \n",
            "\n",
            "https://t.co/zVVywpCKsd\n",
            "RT It is unarguable, Donald Trump is a racist. If you support him you are supporting racism. At this crucial time in the struggle for the soul of our nation, we all must choose. Either embrace his hatred or fight to overcome original sin. Humanity hangs in the balance.\n",
            "RT Donald Trump supporters really are dumb - you can’t make this shit up  #RacistPresident https://t.co/opd6JME6Cx\n",
            "RT These four women are expressing more patriotism in this one press conference than Donald Trump has in his entire life.\n",
            "RT Donald Trump: go back to where you came from\n",
            "\n",
            "Geraldo Rivera: hey that’s racist\n",
            "\n",
            "Brit Hume: no that’s not racist\n",
            "\n",
            "Lindsey Graham: I love racism\n",
            "\n",
            "Susan Collins: I have a hangnail\n",
            "I Think You Should Leave with Donald Trump\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViNC8sn8k8S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(fetched_tweets[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eQW48bvq06Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "api = init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkcfrs6ymvOx",
        "colab_type": "text"
      },
      "source": [
        "# Run Main "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7q0SL7qlQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(search_text): \n",
        "    # creating object of TwitterClient Class \n",
        "    init()\n",
        "    api = init()\n",
        "    # calling function to get tweets \n",
        "    tweets = get_tweets(api, query = search_text, count = 200)\n",
        "    num_tweets = len(tweets)\n",
        "  \n",
        "    # picking positive tweets from tweets \n",
        "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
        "    num_ptweets = len(ptweets)\n",
        "    # percentage of positive tweets \n",
        "    print(\"Positive tweets percentage: {:.2f} %\".format(100*num_ptweets/num_tweets)) \n",
        "    \n",
        "    # picking negative tweets from tweets \n",
        "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
        "    num_ntweets = len(ntweets)\n",
        "    # percentage of negative tweets \n",
        "    print(\"Negative tweets percentage: {:.2f} %\".format(100*num_ntweets/num_tweets)) \n",
        "    \n",
        "    # percentage of neutral tweets \n",
        "    print(\"Neutral tweets percentage: {:.2f} %\".format(100*(num_tweets - num_ntweets - num_ptweets)/num_tweets)) \n",
        "    # average score of tweet sentiments\n",
        "    print(\"Average tweet sentiment score: {:.5f}\".format(get_average_sentiment(tweets)))\n",
        "  \n",
        "    # printing first 5 positive tweets \n",
        "    print(\"\\n\\n\\nPositive tweets:\") \n",
        "    for tweet in ptweets[:5]: \n",
        "        print(\"\\n>>\",tweet['text']) \n",
        "  \n",
        "    # printing first 5 negative tweets \n",
        "    print(\"\\n\\n\\nNegative tweets:\") \n",
        "    for tweet in ntweets[:5]: \n",
        "        print(\"\\n>>\",tweet['text']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1mK_kRFqq-_",
        "colab_type": "code",
        "outputId": "e7f6df1a-fc37-4f4c-b730-a686acfc61dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        }
      },
      "source": [
        "\n",
        "main(search_text='Capitec Bank') "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive tweets percentage: 36.76 %\n",
            "Negative tweets percentage: 13.24 %\n",
            "Neutral tweets percentage: 50.00 %\n",
            "Average tweet sentiment score: 0.14014\n",
            "\n",
            "\n",
            "\n",
            "Positive tweets:\n",
            "\n",
            ">> RT This is absurdity at it's best. \n",
            "\n",
            "Absa established by Antony Edward Rupert, Johan Rupert father\n",
            "Nedbank from Nederland \n",
            "Standard Bank from Britain\n",
            "Capitec from Stellenbosch by Afrikaner students two of them..\n",
            "\n",
            "Who have monopolized financial and banking sector? White warm bodies\n",
            "\n",
            ">> RT #CapitecBank has the strongest brand in SA.\n",
            "\n",
            "The bank was also the strongest brand in the country last year.\n",
            "\n",
            "Castle Lager (up from 21st in 2018) came in second while Black Label came in fourth (after FNB); it's first time in the top-50. https://t.co/oyh9RymfCp #TheMoneyShow\n",
            "\n",
            ">> #CapitecBank has the strongest brand in SA.\n",
            "\n",
            "The bank was also the strongest brand in the country last year.\n",
            "\n",
            "Castle Lager (up from 21st in 2018) came in second while Black Label came in fourth (after FNB); it's first time in the top-50. https://t.co/oyh9RymfCp #TheMoneyShow\n",
            "\n",
            ">> @Prince_ma7 Check out @Hello_DoctorSA  next time, if you have a Capitec account you get the service for free as 1 of our Bank Better Live Better Benefits\n",
            "\n",
            ">> 🔝SneakerTrend_SA 🔝\n",
            "👟Yezzy boost 😱\n",
            "💲R1800💰\n",
            "📦Condition: BNIB (Brand New In Box)\n",
            "🚚Delivery  Nationwide @ an Extra R100\n",
            "📮Strictly payment before delivery\n",
            "💵Payment methods ⤵️⤵️⤵️ • PayPal • fnb\n",
            "💳Capitec bank\n",
            "E-Wallet✔ •Instant Money voucher\n",
            "📲Message us for inquiries https://t.co/tXcei6ZYXb\n",
            "\n",
            "\n",
            "\n",
            "Negative tweets:\n",
            "\n",
            ">> @Radio702 Capitec is starting to get a bad name as the few ATM's it has dotted around seem to be continuously off line or only partially functional. The bank may well have grown too big too fast.\n",
            "\n",
            ">> Ngiyazi uyawathanda amaTender&amp;they work for some people but tenders don't provide employment for our people as much as big production factories,big industries and banks do,Capitec Bank for example employs so many black people it's crazy but it's owned by amabhunu. @NdishiMthembu\n",
            "\n",
            ">> I'm talking mina a black person or black people owning or starting something like Capitec Bank, I'm talking something that serious, that's just an example of the bigger vision I'm taking about that we as black people need to have, ngiyazi uyawathanda amaTender @NdishiMthembu\n",
            "\n",
            ">> RT @Tebogo_Dikobe You are not able to reverse airtime via the Capitec Bank app.  You may contact your service provider for further assistance.\n",
            "\n",
            ">> @CapitecBankSA CAPITEC PLEASE DO SOMETHING WITH YOUR BANK CARDS, WITHIN 2 YEARS I HAVE CHANGED CARDS TWICE DUE TO CHIP MALFUNCTION.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh3Pm7CZgWNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                                                                                                                                                                                            \n",
        "                                                                                                                                                                  \n",
        "                                                   \n",
        "                                                                                                                       \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}